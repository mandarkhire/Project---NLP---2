{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de8de6b",
   "metadata": {},
   "source": [
    "# PART 1 : Blog Classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eba533",
   "metadata": {},
   "source": [
    "## 1. Read and Analyse Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512e3205",
   "metadata": {},
   "source": [
    "### A. Clearly write outcome of data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bcf33dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'gender', 'age', 'topic', 'sign', 'date', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile('blogs.zip', 'r') as zipdata:\n",
    "    data_csv = zipdata.open('blogtext.csv')\n",
    "    \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_csv)\n",
    "\n",
    "print (df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4855c95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>topic</th>\n",
       "      <th>sign</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>14,May,2004</td>\n",
       "      <td>Info has been found (+/- 100 pages,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>13,May,2004</td>\n",
       "      <td>These are the team members:   Drewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>In het kader van kernfusie op aarde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2059027</td>\n",
       "      <td>male</td>\n",
       "      <td>15</td>\n",
       "      <td>Student</td>\n",
       "      <td>Leo</td>\n",
       "      <td>12,May,2004</td>\n",
       "      <td>testing!!!  testing!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3581210</td>\n",
       "      <td>male</td>\n",
       "      <td>33</td>\n",
       "      <td>InvestmentBanking</td>\n",
       "      <td>Aquarius</td>\n",
       "      <td>11,June,2004</td>\n",
       "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id gender  age              topic      sign          date  \\\n",
       "0  2059027   male   15            Student       Leo   14,May,2004   \n",
       "1  2059027   male   15            Student       Leo   13,May,2004   \n",
       "2  2059027   male   15            Student       Leo   12,May,2004   \n",
       "3  2059027   male   15            Student       Leo   12,May,2004   \n",
       "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
       "\n",
       "                                                text  \n",
       "0             Info has been found (+/- 100 pages,...  \n",
       "1             These are the team members:   Drewe...  \n",
       "2             In het kader van kernfusie op aarde...  \n",
       "3                   testing!!!  testing!!!            \n",
       "4               Thanks to Yahoo!'s Toolbar I can ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3ee7c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c23777d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 681284 entries, 0 to 681283\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   id      681284 non-null  int64 \n",
      " 1   gender  681284 non-null  object\n",
      " 2   age     681284 non-null  int64 \n",
      " 3   topic   681284 non-null  object\n",
      " 4   sign    681284 non-null  object\n",
      " 5   date    681284 non-null  object\n",
      " 6   text    681284 non-null  object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 36.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e3dc794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "gender    0\n",
       "age       0\n",
       "topic     0\n",
       "sign      0\n",
       "date      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check the nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8146b29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indUnk                     251015\n",
      "Student                    153903\n",
      "Technology                  42055\n",
      "Arts                        32449\n",
      "Education                   29633\n",
      "Communications-Media        20140\n",
      "Internet                    16006\n",
      "Non-Profit                  14700\n",
      "Engineering                 11653\n",
      "Law                          9040\n",
      "Publishing                   7753\n",
      "Science                      7269\n",
      "Government                   6907\n",
      "Consulting                   5862\n",
      "Religion                     5235\n",
      "Fashion                      4851\n",
      "Marketing                    4769\n",
      "Advertising                  4676\n",
      "BusinessServices             4500\n",
      "Banking                      4049\n",
      "Chemicals                    3928\n",
      "Telecommunications           3891\n",
      "Accounting                   3832\n",
      "Military                     3128\n",
      "Museums-Libraries            3096\n",
      "Sports-Recreation            3038\n",
      "HumanResources               3010\n",
      "RealEstate                   2870\n",
      "Transportation               2326\n",
      "Manufacturing                2272\n",
      "Biotech                      2234\n",
      "Tourism                      1942\n",
      "LawEnforcement-Security      1878\n",
      "Architecture                 1638\n",
      "InvestmentBanking            1292\n",
      "Automotive                   1244\n",
      "Agriculture                  1235\n",
      "Construction                 1093\n",
      "Environment                   592\n",
      "Maritime                      280\n",
      "Name: topic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## topic is the target variable.\n",
    "## Let's check the distribution of topic \n",
    "\n",
    "print (df ['topic'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e487c5",
   "metadata": {},
   "source": [
    "Topic has total 39 distinct values with distribution as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe71ea65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the dataframe: 4768988\n",
      "shape of the dataframe: (681284, 7)\n"
     ]
    }
   ],
   "source": [
    "print ('size of the dataframe:',df.size)\n",
    "print ('shape of the dataframe:',df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3ac960",
   "metadata": {},
   "source": [
    "### B. Clean the Structured Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffb4274",
   "metadata": {},
   "source": [
    "### 2. Preprocess unstructured data to make it consumable for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22264800",
   "metadata": {},
   "source": [
    "A. Eliminate All special Characters and Numbers \n",
    "\n",
    "B. Lowercase all textual data \n",
    "\n",
    "C. Remove all Stopwords \n",
    "\n",
    "D. Remove all extra white spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6269ebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only alphabets\n",
    "import re\n",
    "df.text = df.text.apply(lambda x: re.sub('[^A-Za-z]+', ' ', x))\n",
    "\n",
    "# Convert text to lowercase\n",
    "df.text = df.text.apply(lambda x: x.lower())\n",
    "\n",
    "# Strip unwanted spaces\n",
    "df.text = df.text.apply(lambda x: x.strip())\n",
    "\n",
    "# Remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "df.text = df.text.apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42f892f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'somehow coca cola way summing things well early flagship jingle like buy world coke tune like teach world sing pretty much summed post woodstock era well add much sales catchy tune korea coke theme urllink stop thinking feel pretty much sums lot korea koreans look relaxed couple stopped thinking started feeling course high regard education math logic deep think many koreans really like work emotion anything else westerners seem sublimate moreso least display different way maybe scratch westerners koreans probably pretty similar context different anyways think losing korea repeat stop thinking feel stop thinking feel stop thinking feel everything alright'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cd6fcb",
   "metadata": {},
   "source": [
    "### Build a base Classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b13a06c",
   "metadata": {},
   "source": [
    "A. Create dependent and independent variables \n",
    "\n",
    "[ Hint: Treat ‘topic’ as a Target variable.]\n",
    "\n",
    "B. Split data into train and test. \n",
    "\n",
    "C. Vectorize data using any one vectorizer. \n",
    "\n",
    "D. Build a base model for Supervised Learning - Classification. \n",
    "\n",
    "E. Clearly print Performance Metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e88066c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training utterances: 545027\n",
      "Validation utterances: 136257\n"
     ]
    }
   ],
   "source": [
    "## Split test and train data.\n",
    "## The target variable is topic and training variable is text.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.text.values, df.topic.values, test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "print('Training utterances: {}'.format(X_train.shape[0]))\n",
    "print('Validation utterances: {}'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95f96aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's use TF-IDF vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "505212df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<545027x557241 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 41239292 stored elements in Compressed Sparse Row format>,\n",
       " <136257x557241 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 10212902 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tf = vectorizer.transform(X_train)\n",
    "X_test_tf = vectorizer.transform(X_test)\n",
    "X_train_tf, X_test_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22c664fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa', 'aaa', 'aaaa', 'aaaaa', 'aaaaaa']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's print few feature names\n",
    "vectorizer.get_feature_names()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54364cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's use Naive Bayes classifier for the prediction\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tf, y_train)\n",
    "predicted = clf.predict(X_test_tf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4473a6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.3911872417563868\n",
      "F1 score:  0.39118724175638675\n",
      "Precision score:  0.3911872417563868\n",
      "Recall score:  0.3911872417563868\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print(\"Accuracy Score:\",accuracy_score(y_test, predicted))\n",
    "print('F1 score: ', f1_score(y_test, predicted, average='micro'))\n",
    "print('Precision score: ', precision_score(y_test, predicted,average='micro'))\n",
    "print('Recall score: ', recall_score(y_test, predicted, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067e20b8",
   "metadata": {},
   "source": [
    "### Improve Performance of model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52499df5",
   "metadata": {},
   "source": [
    "A. Experiment with other vectorisers.\n",
    "\n",
    "B. Build classifier Models using other algorithms than base model.\n",
    "\n",
    "C. Tune Parameters/Hyperparameters of the model/s. \n",
    "\n",
    "D. Clearly print Performance Metrics. \n",
    "\n",
    "Hint: Accuracy, Precision, Recall, ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b339a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's use a different vectoriser\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer_cnt = CountVectorizer(binary=True, ngram_range=(1, 4))\n",
    "X_train_cnt = vectorizer_cnt.fit_transform(X_train)\n",
    "X_test_cnt = vectorizer_cnt.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc2208",
   "metadata": {},
   "outputs": [],
   "source": [
    "## print top 5 feature names\n",
    "vectorizer_cnt.get_feature_names()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd025135",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's use Adaboost for the prediction purpose\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abcl = AdaBoostClassifier(n_estimators=40, random_state=1)\n",
    "abcl = abcl.fit(X_train_cnt, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663e1b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_cnt = abcl.predict(X_test_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72504d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy Score with count vectorizer/Adaboost:\",accuracy_score(y_test, predicted_cnt))\n",
    "print('F1 score  with count vectorizer/Adaboost ', f1_score(y_test, predicted_cnt, average='micro'))\n",
    "print('Precision score  with count vectorizer/Adaboost:', precision_score(y_test, predicted_cnt,average='micro'))\n",
    "print('Recall score  with count vectorizer/Adaboost:', recall_score(y_test, predicted_cnt, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77c515d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's try to tune TF-IDF vectorizer\n",
    "## Let's change the parameter max_df to 150 and min_df to 20\n",
    "\n",
    "vectorizer_tuned = TfidfVectorizer(max_df = 150, min_df = 0.01)\n",
    "vectorizer_tuned.fit(X_train)\n",
    "\n",
    "X_train_tuned = vectorizer_tuned.transform(X_train)\n",
    "X_test_tuned = vectorizer_tuned.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc09760",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's print few feature names\n",
    "print (vectorizer_tuned.get_feature_names()[:5])\n",
    "\n",
    "## Let's use BaggingClassifier classifier for the prediction\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(gamma=0.4, C=3)\n",
    "\n",
    "clf.fit(X_train_tuned , y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f5a43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's predict and print the scores\n",
    "predicted_tuned = clf.predict(X_test_tuned)\n",
    "\n",
    "print(\"Accuracy Score with TFIDF tuned vectorizer/svm:\",accuracy_score(y_test, predicted_tuned))\n",
    "print('F1 score  with TFIDF tuned vectorizer/svm ', f1_score(y_test, predicted_tuned, average='micro'))\n",
    "print('Precision score  with TFIDF tuned vectorizer/svm:', precision_score(y_test, predicted_tuned,average='micro'))\n",
    "print('Recall score  with TFIDF tuned vectorizer/svm:', recall_score(y_test, predicted_tuned, average='micro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa01218",
   "metadata": {},
   "source": [
    "#### The Accuracy of the model increases significantly after tuning the TF-IDF vectorizer and using the different classifier like Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad64e35",
   "metadata": {},
   "source": [
    "### Share insights on relative performance comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee9de03",
   "metadata": {},
   "source": [
    "#### A. Which vectorizer performed better? Probable reason?.\n",
    "\n",
    "Ans: TFIDF clearly outperformed over count vectorizer. Probable reason is:\n",
    "\n",
    "TF-IDF is better than Count Vectorizers because it not only focuses on the frequency of words present in the corpus but also provides the importance of the words. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aea2cb",
   "metadata": {},
   "source": [
    "#### B. Which model outperformed? Probable reason? \n",
    "\n",
    "Ans: The model with TFIDF as the vectorizer with tuning added with SVM was the best with the accuracy score of 0.7. TFIDF is the better vectorizer considering the algorithm where it focuses on the importance of the words.\n",
    "SVM algorithm looks at the relations between multiple parameters and hence becomes probably a better classifier for the NLP text classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd82c98",
   "metadata": {},
   "source": [
    "#### C. Which parameter/hyperparameter significantly helped to improve performance?Probable reason?. \n",
    "\n",
    "The right value of gamma in the SVC classifier and the max_df and min_df specifications in the TFIDF vectorizer helped improve the performance significantly\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f0f9ad",
   "metadata": {},
   "source": [
    "#### D. According to you, which performance metric should be given most importance, why?. \n",
    "\n",
    "F1 Score makes more sense in evaluation considering that this provides the right mix of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa189b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
